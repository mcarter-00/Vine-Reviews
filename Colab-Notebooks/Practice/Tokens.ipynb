{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tokens.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOopbQtUgvdRUZnMVvHZ/nP"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"70meFD2xe1-h","colab_type":"code","colab":{}},"source":["# Install Java, Spark, and Findspark\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q http://www-us.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n","!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uKt5XO_7fJDh","colab_type":"code","colab":{}},"source":["# Start Spark session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"Tokens\").getOrCreate()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xQF7mlaJfUHP","colab_type":"code","colab":{}},"source":["# Import the Tokenizer library\n","from pyspark.ml.feature import Tokenizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JoqpSzKrfgL5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"outputId":"65cad7fe-4693-402c-c2f8-b3bd44425a1b","executionInfo":{"status":"ok","timestamp":1588290777478,"user_tz":420,"elapsed":4664,"user":{"displayName":"Maria Carter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEYf613PkPknOgeSZIUX60_i9gLuZ5VAUNcSeD_Cw=s64","userId":"04312149475216757421"}}},"source":["# Create a sample DataFrame\n","dataframe = spark.createDataFrame([\n","                                   (0, \"Spark is great.\"),\n","                                   (1, \"We are learning Spark.\"),\n","                                   (2, \"Spark is better than Hadoop no doubt.\")\n","\n","], [\"id\", \"sentence\"])\n","\n","dataframe.show()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["+---+--------------------+\n","| id|            sentence|\n","+---+--------------------+\n","|  0|     Spark is great.|\n","|  1|We are learning S...|\n","|  2|Spark is better t...|\n","+---+--------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tNKowmT3gd7B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"f9bdb0ff-8d2d-4a87-b0dc-50e7344c788c","executionInfo":{"status":"ok","timestamp":1588290861104,"user_tz":420,"elapsed":425,"user":{"displayName":"Maria Carter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEYf613PkPknOgeSZIUX60_i9gLuZ5VAUNcSeD_Cw=s64","userId":"04312149475216757421"}}},"source":["# Tokenize sentences\n","tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n","tokenizer"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Tokenizer_34ff5c4736b8"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"c6vb-Tk_g4Ds","colab_type":"text"},"source":["The tokenizer function takes input and output parameters. The input passes the name of the column that we want to have tokenized, and the output takes the name that we want the column called."]},{"cell_type":"code","metadata":{"id":"WhcCt7yggzY0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"outputId":"eb0b4d3f-b704-422a-9c19-20fb16c42772","executionInfo":{"status":"ok","timestamp":1588291008394,"user_tz":420,"elapsed":891,"user":{"displayName":"Maria Carter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEYf613PkPknOgeSZIUX60_i9gLuZ5VAUNcSeD_Cw=s64","userId":"04312149475216757421"}}},"source":["# Transform and show the DataFrame\n","tokenized_df = tokenizer.transform(dataframe)\n","tokenized_df.show(truncate=False)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["+---+-------------------------------------+---------------------------------------------+\n","|id |sentence                             |words                                        |\n","+---+-------------------------------------+---------------------------------------------+\n","|0  |Spark is great.                      |[spark, is, great.]                          |\n","|1  |We are learning Spark.               |[we, are, learning, spark.]                  |\n","|2  |Spark is better than Hadoop no doubt.|[spark, is, better, than, hadoop, no, doubt.]|\n","+---+-------------------------------------+---------------------------------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JrReYOXgofoo","colab_type":"text"},"source":["**User-defined functions (UDFs)** are functions created by the user to add custom output columns."]},{"cell_type":"code","metadata":{"id":"pMT_1-jqg4y6","colab_type":"code","colab":{}},"source":["# Create a function to return the length of a list\n","def word_list_length(word_list):\n","\treturn len(word_list)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nfpD2yQXomSr","colab_type":"code","colab":{}},"source":["# Import the udf function, the col function, and IntegerType\n","from pyspark.sql.functions import col, udf\n","from pyspark.sql.types import IntegerType"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AJucNx5ZrGp-","colab_type":"text"},"source":["Import the udf function, the col function to select a column to be passed into a function, and the type IntegerType that will be used in our udf to define the data type of the output"]},{"cell_type":"code","metadata":{"id":"7nPLp-muqOSy","colab_type":"code","colab":{}},"source":["# Create a user defined function\n","count_tokens = udf(word_list_length, IntegerType())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"km96c1b7q6Id","colab_type":"text"},"source":["udf takes in the name of the function as a parameter and the output data type, which is the IntegerType that was just imported"]},{"cell_type":"code","metadata":{"id":"bYYmx71TqO4I","colab_type":"code","colab":{}},"source":["# Create tokenizer\n","tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PqGXdDRcq_yz","colab_type":"code","colab":{}},"source":["# Transform and show the DataFrame\n","tokenized_df = tokenizer.transform(dataframe)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VpuZmrdlr9Qc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"outputId":"2bdb7886-e176-43c1-c5d4-26b1614920a3","executionInfo":{"status":"ok","timestamp":1588293846368,"user_tz":420,"elapsed":1078,"user":{"displayName":"Maria Carter","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEYf613PkPknOgeSZIUX60_i9gLuZ5VAUNcSeD_Cw=s64","userId":"04312149475216757421"}}},"source":["# Select the needed columns and don't truncate results\n","tokenized_df.withColumn(\"tokens\", count_tokens(col(\"words\"))).show(truncate=False)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["+---+-------------------------------------+---------------------------------------------+------+\n","|id |sentence                             |words                                        |tokens|\n","+---+-------------------------------------+---------------------------------------------+------+\n","|0  |Spark is great.                      |[spark, is, great.]                          |3     |\n","|1  |We are learning Spark.               |[we, are, learning, spark.]                  |4     |\n","|2  |Spark is better than Hadoop no doubt.|[spark, is, better, than, hadoop, no, doubt.]|7     |\n","+---+-------------------------------------+---------------------------------------------+------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SGFSeSmXsMDR","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}